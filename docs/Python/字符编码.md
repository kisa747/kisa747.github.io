# 字符编码

## 编码错误

当文件采用 gbk 编码，以 text 形式读取文件时，如果存在非法字符，会提示错误：

test.txt 以 `GBK` 编码，内容如下：

```ini
离离原上草，一岁一枯荣
镕
のニュース

```

> 表面上 test.txt 以 `GBK` 编码，但其实 `䲡㖞㧟` 三个字是以 `b'\xfe\x95\xfeZ\xfec'` 存储的，python 用 gbk 和 utf8 都无法解码，其实应该以 `gb18030`。

```python
>>> b'\xfe\x95\xfeZ\xfec'.decode('gbk')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
UnicodeDecodeError: 'gbk' codec can't decode byte 0xfe in position 0: illegal multibyte sequence
>>> b'\xfe\x95\xfeZ\xfec'.decode('gb18030')
'䲡㖞㧟'
```

使用不同编码读取：

```python
from pathlib import Path
# python 默认以系统编码（cp936）读取，设置为 UTF8 模式则为 utf-8 编码
# 以 gbk 编码读取错误
>>> Path('test.txt').read_text(encoding='gbk')
UnicodeDecodeError: 'gbk' codec can't decode byte 0xfe in position 40: illegal multibyte sequence
# 以 utf8 编码读取错误
>>> Path('test.txt').read_text(encoding='utf8')
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc0 in position 0: invalid start byte
# 以 gb18030 编码读取错误
>>> Path('test.txt').read_text(encoding='gb18030')
'离离原上草，一岁一枯荣\n镕\nのニュース\n䲡㖞㧟'
```

原因分析：

Windows 下，虽然微软名义上采用的编码是 gbk（cp936），其实是微软自己扩展的 gbk 编码，所以 python 使用默认编码（gbk）读取会报错。

采用方法 1 解决最为简单，因为 `GB18030` 是 `gbk` 的超集。

- 方法 1，传入 `encoding='gb18030'` 的参数读取。
- 方法 2，将文本文件转换为 `utf8` 编码后再读取。

>**技巧：** 在使用 gbk、cp936 编码时，强烈推荐使用他们的超集编码 gb18030，更不容易出错。

## 常用编码

参考：<https://docs.python.org/zh-cn/3/library/codecs.html?highlight=cp65001#standard-encodings>

Windows 默认的编码是 `cp936`，常用的编码如下：

|  编码   | 别名                                                         | 语言     |
| :-----: | :----------------------------------------------------------- | :------- |
|  ascii  | 646, us-ascii                                                | 英语     |
| gb2312  | chinese, csiso58gb231280, euc-cn, euccn, eucgb2312-cn, gb2312-1980, gb2312-80, iso-ir-58 | 简体中文 |
|   gbk   | 936, cp936, ms936                                            | 统一汉语 |
| gb18030 | gb18030-2000                                                 | 统一汉语 |
|  utf_8  | U8, UTF, utf8, cp65001                                       | 所有语言 |

## 编码标准

参考：[字符编码的奥秘](<https://www.sinosky.org/the-secret-of-character-encoding.html>)

windows 10 默认编码是 `gbk` （Python 中使用小写），也就是 `cp936` 。1995 年 12 月制定和公布，共 20,902 个汉字。

### GB 2312-80

GB 2312-80 是中华人民共和国制定的第一套关于简体中文字符集和字符编码的国家标准，全称《信息交换用汉字编码字符集·基本集》，1981 年 5 月 1 日实施。只收录 6763 个汉字和包括拉丁字母、希腊字母、日文平假名及片假名、俄语西里尔字母在内的 682 个字符，基本满足了日常需要。虽已被废弃，但仍有许多软件可以支持。

### GBK

GBK 全名为《汉字内码扩展规范 (GBK)》1.0 版，1995 年 12 月制定和公布，属于“技术规范指导性文件”，不属于国家标准。由于 GB 2312-80 收录汉字数量有限，部分简化字、人名（如前总理朱镕基的“镕”字，~~其实这才是关键~~）、繁体字及日韩所用汉字并未收录。于是微软利用 GB 2312-80 未使用的编码空间，收录 GB 13000.1-93（等同于 ISO/IEC 10646.1:1993 和 Unicode 1.1）全部字符（共 20,902 个汉字）制定了 GBK。

### GB 18030-2022

GB 18030-2022 全称《信息技术 中文编码字符集》，是中华人民共和国现时最新的字符集国家标准，2023 年 8 月 1 日实施，与 GB 2312-80 完全兼容，与 GBK 基本兼容（部分不兼容），共收录 70,244 个简繁、日韩汉字和少数民族文字。与 UTF-8 一样都采用可变长度的编码，编码后占用 一、二或四字节。GB 18030-2005 内的单、双字节编码部分，和四字节编码部分收录的中日韩统一表意文字扩展 A 区汉字，为强制性标准，其他部分则属于规范性标准。在中华人民共和国境内发售或使用的所有软件，都需要支持这个同时包含一、二和四字节的编码方式。

虽然 GB 18030-2005 已推行多年，但是直到现在，简体中文版 Windows 上 non-Unicode 程序的默认编码仍然是 GBK（CP 936）。

## 编码问题

python3 内部采用 Unicode

### open() 函数

> open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)

encoding is the name of the encoding used to decode or encode the file. This should only be used in text mode. The default encoding is platform dependent (whatever locale.getpreferredencoding() returns), but any text encoding supported by Python can be used. See the codecs module for the list of supported encodings.

默认打开方式为 `r` ，默认编码为系统默认编码（locale.getpreferredencoding() 方法返回的字符串）。如果是 python 读写的文件，建议加上 utf-8 参数比较好一点。

| Character | Meaning                                                      |
| :-------: | ------------------------------------------------------------ |
|   `'r'`   | open for reading (default)                                   |
|   `'w'`   | open for writing, truncating the file first                  |
|   `'x'`   | open for exclusive creation, failing if the file already exists |
|   `'a'`   | open for writing, appending to the end of the file if it exists |
|   `'b'`   | binary mode                                                  |
|   `'t'`   | text mode (default)                                          |
|   `'+'`   | open a disk file for updating (reading and writing)          |
|   `'U'`   | [universal newlines](https://docs.python.org/3.7/glossary.html#term-universal-newlines) mode (deprecated) |

```python
import locale
>>> locale.getpreferredencoding()  # 根据用户的偏好，返回用于文本数据的 locale encoding。
'utf-8'
>>> locale.getencoding()  # 获取当前的 locale encoding
'cp936'
>>> locale.getlocale()  # 以包含 语言代码，编码格式 的序列形式返回指定语言区域类别的当前设置。
('Chinese (Simplified)_China', '936')
```

Python 的 open 读写文件操作，如果不指定 encoding 参数，默认都会使用操作系统的默认编码。因此写入文件，如果含有中文，那么就会自动编码为 gbk。因此如果想要写入文件用 `utf-8` 编码，应该指定 `encoding='utf-8'` 参数。同样，读取 utf-8 编码的文件，也要指定编码参数。

包括 logging 有中文的话，默认也是 gbk。

>使用 UTF8 模式后，python 读写文件默认采用 utf-8 编码。

Windows10 下默认为（cp936），locale 可以设置为 UTF-8。

设置——时间和语言——区域和语言设置——管理语言设置——更改系统区域设置——勾选“Beta 版：使用 Unicode UTF-8 提供全球语言支持”

修改后：

```python
import locale
>>> locale.getlocale()  # 以包含 语言代码，编码格式 的序列形式返回指定语言区域类别的当前设置。
('Chinese (Simplified)_China', '936')
```

查阅 Python 3 官方文档，cp65001 的解释：Windows only: Windows UTF-8 (`CP_UTF8`)New in version 3.3.

可以理解为 windows 专用的 utf-8 编码了，不建议修改，修改后很多其它的软件会出现问题，包括 Office。

测试使用 cp65001 写入的文件，使用 utf-8 编码也能正常读写。

### 字符串、字节码

Python3 有两种表示字符序列的类型：`bytes` **字节码** 和 `str` **字符串**。

`bytes` 实例包含原始的 8 位值，

`str` 字符串的实例包含 `Unicode` 字符，可以说 python3 的 `str` ，就是 python2 的`Unicode`

网络传输的网页都是 bytes 字节码。

以 `base64` 为例，base64 输入、输出都是 字节码，所以如果输出是字符串，就需要进行转换处理

```python
import base64
h = r'小明同学'
i = h.encode('utf-8')  #指定编码将 字符串 编码为 字节码
j = base64.urlsafe_b64encode(i) #加密后输出 字节码
k = j.decode()  #将 字节码 解码为 字符串
print(f' h:{h}\n i:{i}\n j:{j}\n k:{k}\n')
[输出：]
 h:小明同学
 i:b'\xe5\xb0\x8f\xe6\x98\x8e\xe5\x90\x8c\xe5\xad\xa6'
 j:b'5bCP5piO5ZCM5a2m'
 k:5bCP5piO5ZCM5a2m
```

结论：

> 字符串  >>  字节码：编码，encode
>
> 字节码  >>  字符串：解码，decode

有了这个概念，很多东西就很容易理解了。

```python
import urllib.request
url= r'http://www.hao6v.com/'
with urllib.request.urlopen(url) as response:
    str1 = response.read()  # 读取 response 得到字节码
    str2 = str1.decode('gbk')  # 字节码需要解码，所以 decode
print(str1[:400])
[输出：]
b'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">\r\n<html xmlns="http://www.w3.org/1999/xhtml">\r\n<head>\r\n<meta http-equiv="Content-Type" content="text/html; charset=gb2312" />\r\n<title>\xd7\xee\xd0\xc2\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac\xd7\xee\xd0\xc2\xb5\xe7\xca\xd3\xbe\xe7\xcf\xc2\xd4\xd8\xa3\xac\xb8\xdf\xc7\xe5\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac\xc3\xe2\xb7\xd1\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac6v\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xcd\xf8\xa3\xa8\xbe\xc9\xb0\xe666\xd3\xb0\xca\xd3\xa3\xa9</title>\r\n<meta name="keywords" content="\xd7\xee\xd0\xc2\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac\xb5\xe7\xca\xd3\xbe\xe7'
print(str2[:400])
[输出：]
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312" />
<title>最新电影下载，最新电视剧下载，高清电影下载，免费电影下载，6v电影下载网（旧版66影视）</title>
<meta name="keywords" content="最新电影下载，电视剧下载，高清电影下载" />
<meta name="description" content="6
```

继续探讨，已经了解了编码，我们已经知道 requests 和 BeatifulSoup 都能 使用 chardet 自动识别编码，那就试下吧。

```python
import requests, chardet
from bs4 import BeautifulSoup
r = requests.get(r'http://www.hao6v.com/dy/2018-08-21/MTGHMRJ.html', timeout = 20)

print(r.content[:400])
[输出：]
b'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">\r\n<html xmlns="http://www.w3.org/1999/xhtml">\r\n<head>\r\n<meta http-equiv="Content-Type" content="text/html; charset=gb2312" />\r\n<title>\xd7\xee\xd0\xc2\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac\xd7\xee\xd0\xc2\xb5\xe7\xca\xd3\xbe\xe7\xcf\xc2\xd4\xd8\xa3\xac\xb8\xdf\xc7\xe5\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac\xc3\xe2\xb7\xd1\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac6v\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xcd\xf8\xa3\xa8\xbe\xc9\xb0\xe666\xd3\xb0\xca\xd3\xa3\xa9</title>\r\n<meta name="keywords" content="\xd7\xee\xd0\xc2\xb5\xe7\xd3\xb0\xcf\xc2\xd4\xd8\xa3\xac\xb5\xe7\xca\xd3\xbe\xe7'

chardet.detect(r.content)
[输出：]{'encoding': 'GB2312', 'confidence': 0.99, 'language': 'Chinese'}

print(r.encoding)
[输出：]ISO-8859-1

soup = BeautifulSoup(r.content, 'html.parser')
soup.original_encoding
[输出：]'windows-1252'

soup = BeautifulSoup(r.content, 'lxml')
soup.original_encoding
[输出：]'gb2312'
```

requests 判断出错了，BeautifulSoup 使用 html.parser 也错了，唯有 lxml 是正确的，文档编辑器 Notepad++ 能自动识别编码，Python 如何打开一个文本文件，自动识别编码呢，自己写个函数吧。

```python
def auto_open_text(text_path):
    import chardet
    with open(text_path, 'rb') as f:
        r = f.read()
        char_code = chardet.detect(r)['encoding']
        if char_code == 'GB2312':  # chardet 无法进一步识别处 gbk，只能手动处理了。
            char_code = 'gbk'
        str_1 = r.decode(encoding=char_code)
    return str_1

a = r'D:\Home\Pycharm\测试\tui_jian.txt'
b = auto_open_text(a)
print(b)
[输出：]
镕
离离原上草，一岁一枯荣
の主要ニュース
```

我们来看下各种字符集对‘镕’的编码，gb2313 无法对‘镕’字进行编码，提示错误。gb2313 字符集没有收录‘镕’字。

```python
a = '镕'

print(a)
[输出：]镕

print(a.encode(encoding='utf-8'))
[输出：]b'\xe9\x95\x95'

print(a.encode(encoding='gbk'))
[输出：]b'\xe9F'

print(a.encode(encoding='gb2312'))
[输出：]
Traceback (most recent call last):
  File "D:/Home/Pycharm/测试/ceshi.py", line 57, in <module>
    print(a.encode(encoding='gb2312'))
UnicodeEncodeError: 'gb2312' codec can't encode character '\u9555' in position 0: illegal multibyte sequence

```

继续探讨，调用 windows 命令输出的内容编码是否也是 gbk 呢？

```python
import subprocess
a = subprocess.run(['dir',r'D:\测试'], shell=True, stdout=subprocess.PIPE, encoding='gbk')
[输出：]
CompletedProcess(args=['dir', 'D:\\测试'], returncode=0, stdout=' 驱动器 D 中的卷是 WORK\n 卷的序列号是 000C-8BE6\n\n D:\\测试 的目录\n\n2018/09/01  08:53    <DIR>          .\n2018/09/01  08:53    <DIR>          ..\n2018/09/01  08:53                 0 as12.txt\n2018/09/01  08:53                 0 の主要ニュース.txt\n2018/09/01  08:53                 0 镕.txt\n               3 个文件              0 字节\n               2 个目录 26,959,597,568 可用字节\n')

a = subprocess.run(['dir',r'D:\测试'], shell=True, stdout=subprocess.PIPE, encoding='utf-8')
[输出：]
Traceback (most recent call last):
  File "D:/Home/Pycharm/测试/ceshi.py", line 59, in <module>
    a = subprocess.run(['dir',r'D:\测试'], shell=True, stdout=subprocess.PIPE, encoding='utf-8')
  File "D:\Program Files\Python\lib\subprocess.py", line 455, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
  File "D:\Program Files\Python\lib\subprocess.py", line 907, in communicate
    stdout = self.stdout.read()
  File "D:\Program Files\Python\lib\codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc7 in position 1: invalid continuation byte
```

用 utf-8 参数后，Python 报错。
